{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "import pandas as pd\n",
    "# from project import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataSet = pd.read_csv('card_transdata.csv')\n",
    "dataSet = pd.read_csv('Book1.csv', header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataSet.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4\n",
       "0    A    B  NaN  NaN  NaN\n",
       "1  NaN    B  NaN    D  NaN\n",
       "2  NaN    B    C  NaN  NaN\n",
       "3    A    B  NaN    D  NaN\n",
       "4    A  NaN    C  NaN  NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handle outliers\n",
    "def handle_outliers(df):\n",
    "    # Select numerical columns only\n",
    "    num_cols = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Compute the 1st and 99th percentile of each numerical column\n",
    "    percentiles = np.nanpercentile(num_cols, [1, 99], axis=0)\n",
    "\n",
    "    # Winsorize the numerical columns\n",
    "    num_cols = np.clip(num_cols, percentiles[0], percentiles[1])\n",
    "\n",
    "    # Replace the original numerical columns in the dataframe with the winsorized ones\n",
    "    df[num_cols.columns] = num_cols\n",
    "\n",
    "# handle_outliers(dataSet)\n",
    "\n",
    "# for col in NUM_COL:\n",
    "#     plotting(dataSet, col)\n",
    "\n",
    "# dataSet.describe()\n",
    "(dataSet.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Far_from_home</td>\n",
       "      <td>Close_from_lt</td>\n",
       "      <td>High_ratio</td>\n",
       "      <td>repeat</td>\n",
       "      <td>chip</td>\n",
       "      <td>no_pin</td>\n",
       "      <td>offline</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium_from_home</td>\n",
       "      <td>Close_from_lt</td>\n",
       "      <td>High_ratio</td>\n",
       "      <td>repeat</td>\n",
       "      <td>no_chip</td>\n",
       "      <td>no_pin</td>\n",
       "      <td>offline</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Close_from_home</td>\n",
       "      <td>Medium_from_lt</td>\n",
       "      <td>Low_ratio</td>\n",
       "      <td>repeat</td>\n",
       "      <td>no_chip</td>\n",
       "      <td>no_pin</td>\n",
       "      <td>online</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Close_from_home</td>\n",
       "      <td>Far_from_lt</td>\n",
       "      <td>Low_ratio</td>\n",
       "      <td>repeat</td>\n",
       "      <td>chip</td>\n",
       "      <td>no_pin</td>\n",
       "      <td>online</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Far_from_home</td>\n",
       "      <td>Medium_from_lt</td>\n",
       "      <td>Extreme_ratio</td>\n",
       "      <td>repeat</td>\n",
       "      <td>chip</td>\n",
       "      <td>no_pin</td>\n",
       "      <td>online</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  distance_from_home distance_from_last_transaction  \\\n",
       "0      Far_from_home                  Close_from_lt   \n",
       "1   Medium_from_home                  Close_from_lt   \n",
       "2    Close_from_home                 Medium_from_lt   \n",
       "3    Close_from_home                    Far_from_lt   \n",
       "4      Far_from_home                 Medium_from_lt   \n",
       "\n",
       "  ratio_to_median_purchase_price repeat_retailer used_chip used_pin_number  \\\n",
       "0                     High_ratio          repeat      chip          no_pin   \n",
       "1                     High_ratio          repeat   no_chip          no_pin   \n",
       "2                      Low_ratio          repeat   no_chip          no_pin   \n",
       "3                      Low_ratio          repeat      chip          no_pin   \n",
       "4                  Extreme_ratio          repeat      chip          no_pin   \n",
       "\n",
       "  online_order      fraud  \n",
       "0      offline  not_fraud  \n",
       "1      offline  not_fraud  \n",
       "2       online  not_fraud  \n",
       "3       online  not_fraud  \n",
       "4       online  not_fraud  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##convert the distance from home where >40 is Far and 15<distance<40 is Medium and <15 is Close\n",
    "#use function cut\n",
    "\n",
    "# dataSet['distance_from_home'] = pd.qcut(dataSet['distance_from_home'], q=3, labels=['Close_from_home', 'Medium_from_home', 'Far_from_home'])\n",
    "# dataSet['distance_from_last_transaction'] = pd.qcut(dataSet['distance_from_last_transaction'], q=3, labels=['Close_from_lt', 'Medium_from_lt', 'Far_from_lt'])\n",
    "# dataSet['ratio_to_median_purchase_price'] = pd.qcut(dataSet['ratio_to_median_purchase_price'], q=4, labels=['Low_ratio', 'Medium_ratio', 'High_ratio','Extreme_ratio'])\n",
    "# dataSet['repeat_retailer'] = pd.cut(dataSet['repeat_retailer'], bins=[-0.5, 0.9, np.inf], labels=['no_repeat', 'repeat'])\n",
    "# dataSet['used_chip'] = pd.cut(dataSet['used_chip'], bins=[-0.5, 0.9, np.inf], labels=['no_chip', 'chip'])\n",
    "# dataSet['used_pin_number'] = pd.cut(dataSet['used_pin_number'], bins=[-0.5, 0.9, np.inf], labels=['no_pin', 'pin'])\n",
    "# dataSet['online_order'] = pd.cut(dataSet['online_order'], bins=[-0.5, 0.9, np.inf], labels=['offline', 'online'])\n",
    "# dataSet['fraud'] = pd.cut(dataSet['fraud'], bins=[-0.5, 0.9, np.inf], labels=['not_fraud', 'fraud'])\n",
    "# (dataSet.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 9220.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'nan', 'nan', 'nan'], ['nan', 'B', 'nan', 'D', 'nan'], ['nan', 'B', 'C', 'nan', 'nan'], ['A', 'B', 'nan', 'D', 'nan'], ['A', 'nan', 'C', 'nan', 'nan']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataframe into a list of transactions\n",
    "transactions = []\n",
    "for i in tqdm(range(len(dataSet))):\n",
    "    transactions.append([str(item) for item in dataSet.iloc[i]])\n",
    "    \n",
    "print(transactions[0:5])\n",
    "\n",
    "# Set the minimum support and confidence thresholds\n",
    "min_support = 2/9\n",
    "min_confidence = 0.5\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'A'}, {'B'}, {'D'}, {'C'}]\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of frequent 1-itemsets\n",
    "def generate_frequent_1_itemsets(transactions, min_support):\n",
    "    #key = item, value = count\n",
    "    item_counts = {}\n",
    "    frequent_items = []\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item in item_counts:\n",
    "                item_counts[item] += 1\n",
    "            else:\n",
    "                item_counts[item] = 1\n",
    "    \n",
    "    for item, count in item_counts.items():\n",
    "        if item == 'nan':\n",
    "            continue\n",
    "        support = count / len(transactions)\n",
    "        if support >= min_support:\n",
    "            frequent_items.append(set(item))\n",
    "    return frequent_items\n",
    "frequent_itemsets = generate_frequent_1_itemsets(transactions, min_support)\n",
    "\n",
    "print((frequent_itemsets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemset1 {'A'} itemset2 {'B'}\n",
      "itemset1 {'A'} itemset2 {'D'}\n",
      "itemset1 {'A'} itemset2 {'C'}\n",
      "itemset1 {'B'} itemset2 {'D'}\n",
      "itemset1 {'B'} itemset2 {'C'}\n",
      "itemset1 {'D'} itemset2 {'C'}\n",
      "frequent_itemsets [{'B', 'A'}, {'B', 'D'}, {'B', 'C'}, {'A', 'C'}]\n",
      "itemset1 {'B', 'A'} itemset2 {'B', 'D'}\n",
      "itemset1 {'B', 'A'} itemset2 {'B', 'C'}\n",
      "itemset1 {'B', 'A'} itemset2 {'A', 'C'}\n",
      "itemset1 {'B', 'D'} itemset2 {'B', 'C'}\n",
      "itemset1 {'B', 'D'} itemset2 {'A', 'C'}\n",
      "itemset1 {'B', 'C'} itemset2 {'A', 'C'}\n",
      "frequent_itemsets [{'B', 'A', 'C'}, {'B', 'C', 'A'}]\n",
      "itemset1 {'B', 'A', 'C'} itemset2 {'B', 'C', 'A'}\n",
      "frequent_itemsets [{'B', 'C', 'A'}]\n",
      "frequent_itemsets []\n"
     ]
    }
   ],
   "source": [
    "# Generate frequent k-itemsets\n",
    "from itertools import combinations\n",
    "k = 2\n",
    "\n",
    "while len(frequent_itemsets) > 0:\n",
    "    candidate_itemsets = []\n",
    "    # Generate candidate itemsets of size k\n",
    "    for i in range(len(frequent_itemsets)):\n",
    "        for j in range(i+1, len(frequent_itemsets)):\n",
    "            itemset1 = set(frequent_itemsets[i])\n",
    "            itemset2 = set(frequent_itemsets[j])\n",
    "            print(\"itemset1\", itemset1, \"itemset2\", itemset2)\n",
    "            candidate_itemset = list(itemset1.union(itemset2))\n",
    "            # Prune the candidate itemsets\n",
    "            if all([set(itemset) in frequent_itemsets for itemset in combinations(candidate_itemset, k-1)]):\n",
    "                candidate_itemsets.append(candidate_itemset)\n",
    "            # print(frequent_itemsets)\n",
    "\n",
    "                # if itemset in frequent_itemsets:\n",
    "    \n",
    "                    \n",
    "    # Count the support of each candidate itemset\n",
    "    item_counts = {}\n",
    "    for transaction in transactions:\n",
    "        for candidate_itemset in candidate_itemsets:\n",
    "            if set(candidate_itemset).issubset(set(transaction)):\n",
    "                if str(candidate_itemset) in item_counts:\n",
    "                    item_counts[str(candidate_itemset)] += 1\n",
    "                else:\n",
    "                    item_counts[str(candidate_itemset)] = 1\n",
    "    # Generate a list of frequent k-itemsets\n",
    "    frequent_itemsets = []\n",
    "    for itemset, count in item_counts.items():\n",
    "        support = count / len(transactions)\n",
    "        if support >= min_support:\n",
    "            # print(\"itemset\", itemset)\n",
    "            tempSet = set()\n",
    "            for item in eval(itemset):\n",
    "                tempSet.add(item)\n",
    "            frequent_itemsets.append(tempSet)\n",
    "    \n",
    "    print(\"frequent_itemsets\", frequent_itemsets)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(frequent_itemsets)\n",
    "print(candidate_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
