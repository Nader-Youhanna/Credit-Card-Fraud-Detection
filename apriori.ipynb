{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "import pandas as pd\n",
    "# from project import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.read_csv('card_transdata.csv')\n",
    "# dataSet = pd.read_csv('Book1.csv', header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle outliers\n",
    "def handle_outliers(df):\n",
    "    # Select numerical columns only\n",
    "    num_cols = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Compute the 1st and 99th percentile of each numerical column\n",
    "    percentiles = np.nanpercentile(num_cols, [1, 99], axis=0)\n",
    "\n",
    "    # Winsorize the numerical columns\n",
    "    num_cols = np.clip(num_cols, percentiles[0], percentiles[1])\n",
    "\n",
    "    # Replace the original numerical columns in the dataframe with the winsorized ones\n",
    "    df[num_cols.columns] = num_cols\n",
    "\n",
    "# handle_outliers(dataSet)\n",
    "\n",
    "# for col in NUM_COL:\n",
    "#     plotting(dataSet, col)\n",
    "\n",
    "# dataSet.describe()\n",
    "(dataSet.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##convert the distance from home where >40 is Far and 15<distance<40 is Medium and <15 is Close\n",
    "#use function cut\n",
    "\n",
    "dataSet['distance_from_home'] = pd.qcut(dataSet['distance_from_home'], q=3, labels=['Close_from_home', 'Medium_from_home', 'Far_from_home'])\n",
    "dataSet['distance_from_last_transaction'] = pd.qcut(dataSet['distance_from_last_transaction'], q=3, labels=['Close_from_lt', 'Medium_from_lt', 'Far_from_lt'])\n",
    "dataSet['ratio_to_median_purchase_price'] = pd.qcut(dataSet['ratio_to_median_purchase_price'], q=4, labels=['Low_ratio', 'Medium_ratio', 'High_ratio','Extreme_ratio'])\n",
    "dataSet['repeat_retailer'] = pd.cut(dataSet['repeat_retailer'], bins=[-0.5, 0.9, np.inf], labels=['no_repeat', 'repeat'])\n",
    "dataSet['used_chip'] = pd.cut(dataSet['used_chip'], bins=[-0.5, 0.9, np.inf], labels=['no_chip', 'chip'])\n",
    "dataSet['used_pin_number'] = pd.cut(dataSet['used_pin_number'], bins=[-0.5, 0.9, np.inf], labels=['no_pin', 'pin'])\n",
    "dataSet['online_order'] = pd.cut(dataSet['online_order'], bins=[-0.5, 0.9, np.inf], labels=['offline', 'online'])\n",
    "dataSet['fraud'] = pd.cut(dataSet['fraud'], bins=[-0.5, 0.9, np.inf], labels=['not_fraud', 'fraud'])\n",
    "(dataSet.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe into a list of transactions\n",
    "transactions = []\n",
    "for i in tqdm(range(len(dataSet))):\n",
    "    transactions.append([str(item) for item in dataSet.iloc[i]])\n",
    "    \n",
    "print(transactions[0:5])\n",
    "\n",
    "# Set the minimum support and confidence thresholds\n",
    "min_support = 2/9\n",
    "min_confidence = 0.5\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of frequent 1-itemsets\n",
    "def generate_frequent_1_itemsets(transactions, min_support):\n",
    "    #key = item, value = count\n",
    "    item_counts = {}\n",
    "    frequent_items = []\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item in item_counts:\n",
    "                item_counts[item] += 1\n",
    "            else:\n",
    "                item_counts[item] = 1\n",
    "    print(item_counts)\n",
    "    for item, count in item_counts.items():\n",
    "        # if item == 'nan':\n",
    "        #     continue\n",
    "        support = count / len(transactions)\n",
    "        if support >= min_support:\n",
    "            frequent_items.append({item})\n",
    "    return frequent_items\n",
    "frequent_itemsets = generate_frequent_1_itemsets(transactions, min_support)\n",
    "\n",
    "print((frequent_itemsets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate frequent k-itemsets\n",
    "from itertools import combinations\n",
    "k = 2\n",
    "final_itemSets = []\n",
    "while len(frequent_itemsets) > 0:\n",
    "    candidate_itemsets :list[list] = []\n",
    "    # Generate candidate itemsets of size k\n",
    "    for i in range(len(frequent_itemsets)):\n",
    "        for j in range(i+1, len(frequent_itemsets)):\n",
    "            itemset1 = set(frequent_itemsets[i])\n",
    "            itemset2 = set(frequent_itemsets[j])\n",
    "            # print(\"itemset1\", itemset1, \"itemset2\", itemset2)\n",
    "            candidate_itemset = list(itemset1.union(itemset2))\n",
    "            # Prune the candidate itemsets\n",
    "            if all([set(itemset) in frequent_itemsets for itemset in combinations(candidate_itemset, k-1)]):\n",
    "                candidate_itemsets.append(candidate_itemset)\n",
    "            # print(frequent_itemsets)\n",
    "\n",
    "                # if itemset in frequent_itemsets:\n",
    "    \n",
    "                    \n",
    "    # Count the support of each candidate itemset\n",
    "    item_counts = {}\n",
    "    for transaction in tqdm(transactions):\n",
    "        for candidate_itemset in candidate_itemsets:\n",
    "            if set(candidate_itemset).issubset(set(transaction)):\n",
    "                item = sorted(candidate_itemset)\n",
    "                if str(item) in item_counts:\n",
    "                    item_counts[str(item)] += 1\n",
    "                else:\n",
    "                    item_counts[str(item)] = 1\n",
    "\n",
    "    # print(\"item_counts\", item_counts)\n",
    "    # Generate a list of frequent k-itemsets\n",
    "    \n",
    "    frequent_itemsets = []\n",
    "    for itemset, count in item_counts.items():\n",
    "        support = count / len(transactions)\n",
    "        if support >= min_support:\n",
    "            # print(\"itemset\", itemset)\n",
    "            tempSet = set()\n",
    "            for item in eval(itemset):\n",
    "                tempSet.add(item)\n",
    "            frequent_itemsets.append(tempSet)\n",
    "    if len(frequent_itemsets) > 0:\n",
    "        final_itemSets = frequent_itemsets\n",
    "    \n",
    "    k += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_itemSets)\n",
    "frequent_itemsets = final_itemSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules from frequent itemsets\n",
    "def generate_association_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for itemset in tqdm(frequent_itemsets):\n",
    "        if len(itemset) > 1:\n",
    "            for i in range(1, len(itemset)):\n",
    "                for left in combinations(itemset, i):\n",
    "                    right = list(set(itemset) - set(left))\n",
    "                    left_support = 0\n",
    "                    right_support = 0\n",
    "                    itemset_support = 0\n",
    "                    for transaction in transactions:\n",
    "                        if set(left).issubset(set(transaction)):\n",
    "                            left_support += 1\n",
    "                        if set(right).issubset(set(transaction)):\n",
    "                            right_support += 1\n",
    "                        if set(itemset).issubset(set(transaction)):\n",
    "                            itemset_support += 1\n",
    "                    left_support /= len(transactions)\n",
    "                    right_support /= len(transactions)\n",
    "                    itemset_support /= len(transactions)\n",
    "                    confidence = itemset_support / left_support\n",
    "                    lift = confidence / right_support\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((left, right, confidence, lift))\n",
    "    return rules\n",
    "\n",
    "association_rules = generate_association_rules(frequent_itemsets, min_confidence)\n",
    "\n",
    "# Print the frequent itemsets and association rules\n",
    "print(\"Frequent itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "print(\"Association rules:\")\n",
    "for rule in association_rules:\n",
    "    print(\"{} => {} (confidence: {:.2f}, lift: {:.2f})\".format(rule[0], rule[1], rule[2], rule[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets:\n",
      "[{'not_fraud', 'offline', 'no_pin', 'repeat', 'no_chip'}, {'not_fraud', 'online', 'no_pin', 'repeat', 'no_chip'}, {'chip', 'not_fraud', 'online', 'no_pin', 'repeat'}]\n",
      "Association rules:\n",
      "('offline',) => ['repeat', 'no_chip', 'no_pin', 'not_fraud'] (confidence: 0.51, lift: 1.12)\n",
      "('not_fraud', 'offline') => ['repeat', 'no_chip', 'no_pin'] (confidence: 0.52, lift: 1.01)\n",
      "('offline', 'no_pin') => ['repeat', 'no_chip', 'not_fraud'] (confidence: 0.57, lift: 1.10)\n",
      "('offline', 'repeat') => ['no_chip', 'no_pin', 'not_fraud'] (confidence: 0.58, lift: 1.12)\n",
      "('offline', 'no_chip') => ['repeat', 'no_pin', 'not_fraud'] (confidence: 0.79, lift: 1.10)\n",
      "('not_fraud', 'offline', 'no_pin') => ['repeat', 'no_chip'] (confidence: 0.58, lift: 1.01)\n",
      "('not_fraud', 'offline', 'repeat') => ['no_chip', 'no_pin'] (confidence: 0.58, lift: 1.00)\n",
      "('not_fraud', 'offline', 'no_chip') => ['repeat', 'no_pin'] (confidence: 0.80, lift: 1.01)\n",
      "('offline', 'no_pin', 'repeat') => ['no_chip', 'not_fraud'] (confidence: 0.65, lift: 1.10)\n",
      "('offline', 'no_pin', 'no_chip') => ['repeat', 'not_fraud'] (confidence: 0.88, lift: 1.09)\n",
      "('offline', 'repeat', 'no_chip') => ['no_pin', 'not_fraud'] (confidence: 0.89, lift: 1.10)\n",
      "('not_fraud', 'offline', 'no_pin', 'repeat') => ['no_chip'] (confidence: 0.65, lift: 1.00)\n",
      "('not_fraud', 'offline', 'no_pin', 'no_chip') => ['repeat'] (confidence: 0.89, lift: 1.01)\n",
      "('not_fraud', 'offline', 'repeat', 'no_chip') => ['no_pin'] (confidence: 0.90, lift: 1.00)\n",
      "('offline', 'no_pin', 'repeat', 'no_chip') => ['not_fraud'] (confidence: 0.99, lift: 1.09)\n",
      "('online', 'no_chip') => ['repeat', 'no_pin', 'not_fraud'] (confidence: 0.66, lift: 0.92)\n",
      "('not_fraud', 'online', 'no_pin') => ['repeat', 'no_chip'] (confidence: 0.56, lift: 0.97)\n",
      "('not_fraud', 'online', 'repeat') => ['no_chip', 'no_pin'] (confidence: 0.56, lift: 0.96)\n",
      "('not_fraud', 'online', 'no_chip') => ['repeat', 'no_pin'] (confidence: 0.77, lift: 0.97)\n",
      "('not_fraud', 'no_pin', 'no_chip') => ['repeat', 'online'] (confidence: 0.54, lift: 0.94)\n",
      "('not_fraud', 'repeat', 'no_chip') => ['no_pin', 'online'] (confidence: 0.54, lift: 0.93)\n",
      "('online', 'no_pin', 'repeat') => ['no_chip', 'not_fraud'] (confidence: 0.54, lift: 0.93)\n",
      "('online', 'no_pin', 'no_chip') => ['repeat', 'not_fraud'] (confidence: 0.73, lift: 0.91)\n",
      "('online', 'repeat', 'no_chip') => ['no_pin', 'not_fraud'] (confidence: 0.75, lift: 0.92)\n",
      "('no_pin', 'repeat', 'no_chip') => ['not_fraud', 'online'] (confidence: 0.54, lift: 0.95)\n",
      "('not_fraud', 'online', 'no_pin', 'repeat') => ['no_chip'] (confidence: 0.63, lift: 0.97)\n",
      "('not_fraud', 'online', 'no_pin', 'no_chip') => ['repeat'] (confidence: 0.87, lift: 0.99)\n",
      "('not_fraud', 'online', 'repeat', 'no_chip') => ['no_pin'] (confidence: 0.88, lift: 0.98)\n",
      "('not_fraud', 'no_pin', 'repeat', 'no_chip') => ['online'] (confidence: 0.61, lift: 0.94)\n",
      "('online', 'no_pin', 'repeat', 'no_chip') => ['not_fraud'] (confidence: 0.83, lift: 0.91)\n",
      "('chip', 'online') => ['repeat', 'no_pin', 'not_fraud'] (confidence: 0.71, lift: 0.99)\n",
      "('chip', 'no_pin') => ['repeat', 'not_fraud', 'online'] (confidence: 0.51, lift: 1.03)\n",
      "('chip', 'repeat') => ['not_fraud', 'no_pin', 'online'] (confidence: 0.53, lift: 1.05)\n",
      "('chip', 'not_fraud', 'online') => ['repeat', 'no_pin'] (confidence: 0.79, lift: 0.99)\n",
      "('chip', 'not_fraud', 'no_pin') => ['repeat', 'online'] (confidence: 0.55, lift: 0.97)\n",
      "('chip', 'not_fraud', 'repeat') => ['no_pin', 'online'] (confidence: 0.56, lift: 0.96)\n",
      "('chip', 'online', 'no_pin') => ['repeat', 'not_fraud'] (confidence: 0.79, lift: 0.98)\n",
      "('chip', 'online', 'repeat') => ['no_pin', 'not_fraud'] (confidence: 0.81, lift: 0.99)\n",
      "('chip', 'no_pin', 'repeat') => ['not_fraud', 'online'] (confidence: 0.58, lift: 1.03)\n",
      "('chip', 'not_fraud', 'online', 'no_pin') => ['repeat'] (confidence: 0.88, lift: 1.00)\n",
      "('chip', 'not_fraud', 'online', 'repeat') => ['no_pin'] (confidence: 0.89, lift: 0.99)\n",
      "('chip', 'not_fraud', 'no_pin', 'repeat') => ['online'] (confidence: 0.63, lift: 0.97)\n",
      "('chip', 'online', 'no_pin', 'repeat') => ['not_fraud'] (confidence: 0.90, lift: 0.98)\n"
     ]
    }
   ],
   "source": [
    "print(\"Frequent itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "print(\"Association rules:\")\n",
    "for rule in association_rules:\n",
    "    print(\"{} => {} (confidence: {:.2f}, lift: {:.2f})\".format(rule[0], rule[1], rule[2], rule[3]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent itemsets:\n",
    "[{'not_fraud', 'offline', 'no_pin', 'repeat', 'no_chip'}, {'not_fraud', 'online', 'no_pin', 'repeat', 'no_chip'},</br> \n",
    "{'chip', 'not_fraud', 'online', 'no_pin', 'repeat'}]\n",
    "## Association rules:\n",
    "('offline',) => ['repeat', 'no_chip', 'no_pin', 'not_fraud'] (confidence: 0.51, lift: 1.12)</br>\n",
    "('not_fraud', 'offline') => ['repeat', 'no_chip', 'no_pin'] (confidence: 0.52, lift: 1.01)</br>\n",
    "('offline', 'no_pin') => ['repeat', 'no_chip', 'not_fraud'] (confidence: 0.57, lift: 1.10)</br>\n",
    "('offline', 'repeat') => ['no_chip', 'no_pin', 'not_fraud'] (confidence: 0.58, lift: 1.12)</br>\n",
    "('offline', 'no_chip') => ['repeat', 'no_pin', 'not_fraud'] (confidence: 0.79, lift: 1.10)</br>\n",
    "('not_fraud', 'offline', 'no_pin') => ['repeat', 'no_chip'] (confidence: 0.58, lift: 1.01)</br>\n",
    "('not_fraud', 'offline', 'repeat') => ['no_chip', 'no_pin'] (confidence: 0.58, lift: 1.00)</br>\n",
    "('not_fraud', 'offline', 'no_chip') => ['repeat', 'no_pin'] (confidence: 0.80, lift: 1.01)</br>\n",
    "('offline', 'no_pin', 'repeat') => ['no_chip', 'not_fraud'] (confidence: 0.65, lift: 1.10)</br>\n",
    "('offline', 'no_pin', 'no_chip') => ['repeat', 'not_fraud'] (confidence: 0.88, lift: 1.09)</br>\n",
    "('offline', 'repeat', 'no_chip') => ['no_pin', 'not_fraud'] (confidence: 0.89, lift: 1.10)</br>\n",
    "('not_fraud', 'offline', 'no_pin', 'repeat') => ['no_chip'] (confidence: 0.65, lift: 1.00)</br>\n",
    "('not_fraud', 'offline', 'no_pin', 'no_chip') => ['repeat'] (confidence: 0.89, lift: 1.01)</br>\n",
    "('not_fraud', 'offline', 'repeat', 'no_chip') => ['no_pin'] (confidence: 0.90, lift: 1.00)</br>\n",
    "('offline', 'no_pin', 'repeat', 'no_chip') => ['not_fraud'] (confidence: 0.99, lift: 1.09)</br>\n",
    "('online', 'no_chip') => ['repeat', 'no_pin', 'not_fraud'] (confidence: 0.66, lift: 0.92)</br>\n",
    "('not_fraud', 'online', 'no_pin') => ['repeat', 'no_chip'] (confidence: 0.56, lift: 0.97)</br>\n",
    "('not_fraud', 'online', 'repeat') => ['no_chip', 'no_pin'] (confidence: 0.56, lift: 0.96)</br>\n",
    "('not_fraud', 'online', 'no_chip') => ['repeat', 'no_pin'] (confidence: 0.77, lift: 0.97)</br>\n",
    "('not_fraud', 'no_pin', 'no_chip') => ['repeat', 'online'] (confidence: 0.54, lift: 0.94)</br>\n",
    "('not_fraud', 'repeat', 'no_chip') => ['no_pin', 'online'] (confidence: 0.54, lift: 0.93)</br>\n",
    "('online', 'no_pin', 'repeat') => ['no_chip', 'not_fraud'] (confidence: 0.54, lift: 0.93)</br>\n",
    "('online', 'no_pin', 'no_chip') => ['repeat', 'not_fraud'] (confidence: 0.73, lift: 0.91)</br>\n",
    "('online', 'repeat', 'no_chip') => ['no_pin', 'not_fraud'] (confidence: 0.75, lift: 0.92)</br>\n",
    "('no_pin', 'repeat', 'no_chip') => ['not_fraud', 'online'] (confidence: 0.54, lift: 0.95)</br>\n",
    "('not_fraud', 'online', 'no_pin', 'repeat') => ['no_chip'] (confidence: 0.63, lift: 0.97)</br>\n",
    "('not_fraud', 'online', 'no_pin', 'no_chip') => ['repeat'] (confidence: 0.87, lift: 0.99)</br>\n",
    "('not_fraud', 'online', 'repeat', 'no_chip') => ['no_pin'] (confidence: 0.88, lift: 0.98)</br>\n",
    "('not_fraud', 'no_pin', 'repeat', 'no_chip') => ['online'] (confidence: 0.61, lift: 0.94)</br>\n",
    "('online', 'no_pin', 'repeat', 'no_chip') => ['not_fraud'] (confidence: 0.83, lift: 0.91)</br>\n",
    "('chip', 'online') => ['repeat', 'no_pin', 'not_fraud'] (confidence: 0.71, lift: 0.99)</br>\n",
    "('chip', 'no_pin') => ['repeat', 'not_fraud', 'online'] (confidence: 0.51, lift: 1.03)</br>\n",
    "('chip', 'repeat') => ['not_fraud', 'no_pin', 'online'] (confidence: 0.53, lift: 1.05)</br>\n",
    "('chip', 'not_fraud', 'online') => ['repeat', 'no_pin'] (confidence: 0.79, lift: 0.99)</br>\n",
    "('chip', 'not_fraud', 'no_pin') => ['repeat', 'online'] (confidence: 0.55, lift: 0.97)</br>\n",
    "('chip', 'not_fraud', 'repeat') => ['no_pin', 'online'] (confidence: 0.56, lift: 0.96)</br>\n",
    "('chip', 'online', 'no_pin') => ['repeat', 'not_fraud'] (confidence: 0.79, lift: 0.98)</br>\n",
    "('chip', 'online', 'repeat') => ['no_pin', 'not_fraud'] (confidence: 0.81, lift: 0.99)</br>\n",
    "('chip', 'no_pin', 'repeat') => ['not_fraud', 'online'] (confidence: 0.58, lift: 1.03)</br>\n",
    "('chip', 'not_fraud', 'online', 'no_pin') => ['repeat'] (confidence: 0.88, lift: 1.00)</br>\n",
    "('chip', 'not_fraud', 'online', 'repeat') => ['no_pin'] (confidence: 0.89, lift: 0.99)</br>\n",
    "('chip', 'not_fraud', 'no_pin', 'repeat') => ['online'] (confidence: 0.63, lift: 0.97)</br>\n",
    "('chip', 'online', 'no_pin', 'repeat') => ['not_fraud'] (confidence: 0.90, lift: 0.98)</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
