{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import everything for data preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import everything for model building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "\n",
    "CAT_COL = [\"repeat_retailer\",\"used_chip\",\"used_pin_number\",\"online_order\",\"fraud\"]\n",
    "NON_CAT_COL = [\"distance_from_home\",\"distance_from_last_transaction\",\"ratio_to_median_purchase_price\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_from_home [57.87785658 10.8299427   5.09107949 ...  2.91485699  4.25872939\n",
      " 58.10812496]\n",
      "distance_from_last_transaction [0.31114001 0.1755915  0.80515259 ... 1.47268669 0.24202337 0.31811012]\n",
      "ratio_to_median_purchase_price [1.94593998 1.29421881 0.42771456 ... 0.21807549 0.47582206 0.38691985]\n",
      "repeat_retailer [1. 0.]\n",
      "used_chip [1. 0.]\n",
      "used_pin_number [0. 1.]\n",
      "online_order [0. 1.]\n",
      "fraud [0. 1.]\n",
      "204124\n",
      "205221\n"
     ]
    }
   ],
   "source": [
    "dataSet = pd.read_csv('card_transdata.csv')\n",
    "#print levels of every column\n",
    "for col in dataSet.columns:\n",
    "    print(col, dataSet[col].unique())\n",
    "\n",
    "dataSet.dropna(inplace=True)\n",
    "\n",
    "#count rows that have used_chip = 0, used_pin_number = 0, online_order = 0\n",
    "#this means that the payment happened through wireless payment\n",
    "print(dataSet[(dataSet['used_chip'] == 0) & (dataSet['used_pin_number'] == 0) & (dataSet['online_order'] == 0)].shape[0])\n",
    "\n",
    "#count rows that have used_chip = 1, used_pin_number = 0, online_order = 1\n",
    "#this means that the payment happened using NFC technology\n",
    "print(dataSet[(dataSet['used_chip'] == 1) & (dataSet['used_pin_number'] == 0) & (dataSet['online_order'] == 1)].shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df):\n",
    "#Handle outliers\n",
    "    # Select numerical columns only\n",
    "    num_cols = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Compute the 1st and 99th percentile of each numerical column\n",
    "    percentiles = np.nanpercentile(num_cols, [1, 99], axis=0)\n",
    "\n",
    "    # Winsorize the numerical columns\n",
    "    num_cols = np.clip(num_cols, percentiles[0], percentiles[1])\n",
    "\n",
    "    # Replace the original numerical columns in the dataframe with the winsorized ones\n",
    "    df[num_cols.columns] = num_cols\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardDev(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        if feature_name in CAT_COL:\n",
    "            continue\n",
    "        mean_value = df[feature_name].mean()\n",
    "        std_value = df[feature_name].std()\n",
    "        result[feature_name] = (df[feature_name] - mean_value) / std_value\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "dataSet = standardDev(dataSet)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataSet.drop('fraud',axis=1), dataSet['fraud'], test_size=0.3, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic regression score:  95.84899999999999 %\n"
     ]
    }
   ],
   "source": [
    "#implement logistic regression\n",
    "logisticRegr = LogisticRegression(max_iter=1000)\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "predictions = logisticRegr.predict(X_test)\n",
    "print(\"logistic regression predictions: \", predictions[:10])\n",
    "score = logisticRegr.score(X_test, y_test)\n",
    "print(\"Logisitic regression score: \", score*100, \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
