{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession\n",
    "ss = SparkSession.builder.appName(\"MapReduceExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(distance_from_home=57.87785658389723, distance_from_last_transaction=0.3111400080477545, ratio_to_median_purchase_price=1.9459399775518593, repeat_retailer=1.0, used_chip=1.0, used_pin_number=0.0, online_order=0.0, fraud=0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Load Data to RDD\n",
    "dataRDD = ss.read.csv(\"card_transdata.csv\", header=True, inferSchema=True).rdd\n",
    "#print first rows\n",
    "print(dataRDD.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(x1, x2):\n",
    "    # Euclidean distance\n",
    "    distance = np.linalg.norm(x1-x2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainRDD, testRDD = dataRDD.randomSplit([0.8, 0.2], seed=42)\n",
    "#drop fraud column from testRDD\n",
    "testlabels = testRDD.map(lambda x: x[-1])\n",
    "testRDD = testRDD.map(lambda x: x[:-1])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNMapReduce():\n",
    "    \n",
    "    testPredictions = []\n",
    "    k = 3\n",
    "    testPoints = testRDD.collect()[200:500]  \n",
    "\n",
    "    for testPoint in tqdm(testPoints):\n",
    "        fraudDetection = trainRDD.map(lambda x: (None, (x,calculateDistance(testPoint, np.array(x[:-1])))))\n",
    "        fraudDetection = fraudDetection.takeOrdered(k, key=lambda x: x[1][1])\n",
    "        results = fraudDetection\n",
    "        countFraud = 0\n",
    "        for result in results:\n",
    "            if  result[1][0][7] == 1:\n",
    "                countFraud += 1\n",
    "        \n",
    "        if countFraud > k/2:\n",
    "            testPredictions.append(1)\n",
    "        else:\n",
    "            testPredictions.append(0)\n",
    "\n",
    "    return testPredictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def testKNN():\n",
    "    testPredictions = np.array(KNNMapReduce)\n",
    "    print(testPredictions)\n",
    "    testLabels = np.array(testlabels.collect()[200:500])\n",
    "    print(testLabels)\n",
    "    accuracy = np.sum(testPredictions == testLabels)/len(testLabels)\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save testPredictions and test labels to same text file\n",
    "# #open file\n",
    "# f = open(\"testPredictions2.txt\", \"w\")\n",
    "# #write testPredictions and test labels beside each other to file\n",
    "# for i in range(len(testPredictions)):\n",
    "#     f.write(str(testPredictions[i]) + \" \" + str(testLabels[i]) + \"\\n\")\n",
    "# #close file\n",
    "# f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering (K-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calCentroid(x):\n",
    "        centroid = np.mean(x, axis=0)\n",
    "        return centroid\n",
    "\n",
    "def initializeCentroids(dataRDD, k):\n",
    "    centroids = dataRDD.takeSample(False, k, seed=42)\n",
    "    return centroids\n",
    "\n",
    "def assignCluster(x, centroids) -> int:\n",
    "    distances = np.zeros(len(centroids))\n",
    "    for i in range(len(centroids)):\n",
    "        distances[i]= calculateDistance(x, centroids[i])\n",
    "    cluster = np.argmin(distances)\n",
    "    return cluster\n",
    "\n",
    "def KMeans(iter: int = 5):\n",
    "    \n",
    "\n",
    "    k = 2\n",
    "    centroids = initializeCentroids(dataRDD, k)\n",
    "    centroids = np.array(centroids)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Training KNN... {iter} iterations\")\n",
    "    for i in tqdm(range(iter)):\n",
    "        #Train KNN\n",
    "        fraudDetection = dataRDD.map(lambda x: (assignCluster(np.array(x),centroids), x))\n",
    "        fraudDetection = fraudDetection.groupByKey().map(lambda x: (x[0], list(x[1])))\n",
    "        fraudDetection = fraudDetection.reduceByKey(lambda x,y: x+y)\n",
    "        fraudDetection = fraudDetection.map(lambda x: (x[0], calCentroid(np.array(x[1]))))\n",
    "        fraudDetection = fraudDetection.collect()\n",
    "\n",
    "        # print(fraudDetection.take(11))\n",
    "\n",
    "        firstCentroid = fraudDetection[0]\n",
    "        secondCentroid = fraudDetection[1]\n",
    "\n",
    "        # print(firstCentroid)\n",
    "        # print(secondCentroid)\n",
    "\n",
    "        centroids = np.array([firstCentroid[1], secondCentroid[1]])\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "def KMeansWSS(centroids, dataRDD):\n",
    "    WSS = 0\n",
    "    data = dataRDD.collect()\n",
    "    print(\"Calculating WSS...\")\n",
    "    for i in tqdm(range(len(data))):\n",
    "        tstPt = np.array(data[i])\n",
    "        cluster = assignCluster(tstPt, centroids)\n",
    "        WSS += calculateDistance(tstPt, centroids[cluster]) ** 2\n",
    "\n",
    "    return WSS\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN... 2 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:42<00:00, 81.02s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "centroids = KMeans(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating WSS...\n",
      "WSS:  3311305539.2410283\n"
     ]
    }
   ],
   "source": [
    "WSS = KMeansWSS(centroids, dataRDD)\n",
    "print(\"WSS: \", WSS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
